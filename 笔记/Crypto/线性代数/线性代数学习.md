# 线性代数学习

没找到别的适合我这个水平的数论课程了，所以来学线性代数。

### Cauchy-Schwarz 不等式

如果$\vec{x},\vec{y}\in \real^n$，那么$|\vec{x}·\vec{y}|<=||\vec{x}||\vec{y}||$

$|\vec{x}·\vec{y}|=||\vec{x}||\vec{y}||\iff\vec{x}=c\vec{y}$

在向量的运算中，·表示点乘，x表示叉乘，和平时的理解有点不一样。

点乘中，交换律和分配律这类运算规律同样适用。一个n维向量的模长为$||\vec{v}||=\sqrt{v^2+v^2+v^2+...v+v^2}$，v表示v1，v2，v3，vn……也就是等于v这个向量与自己的点乘的开方。$||\vec{v}||^2=\vec{v}·\vec{v}$
 
### 三角不等式

$||\vec{x}+\vec{y}||<=||\vec{x}||+||\vec{y}||$

![vector_triangle_inequality](../images/vector_triangle_inequality.png)

加上这张图会更简单。其实就是初中学的三角形三条边的性质：两边之和大于第三边。这里还多了个等于的情况，因为向量y和向量x可能共线。

$(\vec{a}·\vec{b})=||\vec{a}||||\vec{b}||cos\theta$。$\theta$为两个向量之间的夹角。证明要用余弦定理，视频里的证明有点乱就不放了。这个公式在二维向量的情况下相信大家已经都用过很多次了，推广到多维同样适用。

另外还有一点新概念。当夹角为90度的时候，上面公式的值为0，因为cos 90等于0。如果x向量和y向量都不是0，则我们说两者垂直并正交。如果两者中有一个是0，则我们说两者正交。0向量与任何向量都正交，包括自己。

![plane_in_r3](../images/plane_in_r3.png)

这张图讲了如何利用法向量和一个点在r3中定义一个平面。方法就是把表示那个点的向量与向量x相减，结果再与法向量进行点乘，最终结果化简就是所求的方程。

![plane](../images/plane.png)

关于平面标准方程的补充。通过标准方程找法向量很简单。标准方程为$Ax+By+Cz=D$，那么$\vec{n}=Ai+Bj+Ck$,其中i，j和k是标准向量。

![distance](../images/distance.png)

上图展示了如何找到不在平面上的点与平面的距离。

### 叉乘

![cross_product](../images/cross_product.png)

叉乘的使用范围没有点乘广。点乘在任意维度的向量中都被定义，而叉乘仅存在于三维向量，即$R^3$。叉乘表示为$\vec{a}$ x $\vec{b}$,结果是一个三维向量，这个向量与a和b都正交。如何计算图中有写，稍微有点复杂。同时还有个跟点乘相对的公式:$||\vec{a}$ x $\vec{b}||=||\vec{a}||||\vec{b}||sin\theta$。

![matrix_equation](../images/matrix_equation.png)

???怎么突然就用矩阵来解方程了？还是不定方程，我都还没学……会。没事以后还能补。

![normal_equation](../images/normal_equation.png)

这个正常了，使用矩阵解3元一次方程组。思路也很简单，首先把第一个方程的x作为主元，剩下两行在x的位置需要利用相加相减等方法消去数字，得到0。第二个方程的y作为主元，第三个方程的z作为主元。最后得到的矩阵就是这个方程组的解。其实和平常解的方法是一样的，都是尽量消元，只是矩阵解法要保证主元所在的列只有自己不是0。

![no_solution](../images/no_solution.png)

这种情况下方程组无解。此方程的增广矩阵消元到最后得到了0=-4，而这是不可能的，从而无解。有解的情况是0=0。如果一个方程组消元后的矩阵最后一行全是0且等于0，并有无关主元的自由变量，那么该方程组有无数个解；如果没有则恰好有一个解。

![matrix_vector](../images/matrix_vector.png)

以上是如何求一个矩阵的向量的乘积。矩阵的列数必须和向量的标量的数量相同。

![null_space_intro](../images/null_space_intro.png)

首先先来复习一下子空间的定义。子空间S满足$\vec{0}\in S;\vec{v1},\vec{v2}\in S\rArr \vec{v1}+\vec{v2}\in S;C\in \real,C\vec{v}\in S$。即子空间S中有向量0；如果向量v1和v2都在S中，则v1+v1也在S中，对加法封闭；C是任意实数，向量v1在S中，C乘v1在S中，对乘法封闭。N(A)指的是找到满足方程$A\vec{x}=0$的$\vec{x}$所构成的集合，即零空间。

![find_null_space](../images/find_null_space.png)

这张图算出来矩阵A的零空间是两个矩阵张成的空间，而那两个矩阵由矩阵A的增广矩阵得来.我看不懂但我大受震撼。

![nullspace_linear_independent](../images/null_space_linear_independent.png)

如何利用矩阵A的零空间来判断矩阵A是否线性无关？如果矩阵A得零空间仅包含一个元素，即向量0，意味着方程的解只有0，因此矩阵线性无关。线性相关代表一组向量中的一部分可以用各种线性组合来构成这组向量中的另一个向量；线性无关代表无论如何线性组合都无法构成另一个。

![column_space](../images/column_space.png)

一个矩阵的列空间是其所有列向量所张成的空间。

一个子空间的维数等于该子空间一个基底的元素的个数。对于给定的子空间的所有基底，都含有相同数量的元素。任意一个矩阵的零度等于其自由变量的数量（该矩阵行简化阶梯形中非主列的个数。矩阵的秩（rank）等于矩阵的行简化阶梯形的主列的数量。就记一下概念了，这个课程还没教过什么是行简化阶梯形。

![codomain](../images/codomain.png)

函数大家肯定都不陌生，不过初中学的函数只提到了值域（range）这个概念，而现在引入了上域（codomain）。值域是上域的子集合，拿视频里的向量函数h来举例最容易理解。h(x1,x2)=(x1+x2,x2-x1,x2*x1)接收一个二维向量，返回三维向量，那么它的上域就是就是$R^3$中的任意向量，比如(5,1,0)。但(5,1,0)这个向量是不可能成为h函数的输出的，所以不在值域内。

函数可以看作是两块区域间的映射。比如有$R^n$和$R^m$两块区域，$R^n$中的任意元素经过任意变换可以得到$R^m$中的任意元素，这就是一种映射关系。线性代数中可以把向量之间的映射看作一种变换，用T表示。

### 线性变换

线性变换$T:R^n\rArr R^m$满足$\vec{a},\vec{b}\in R^n;T(\vec{a}+\vec{b})=T(\vec{a})+T(\vec{b});T(c\vec{a})=cT(\vec{a})$

矩阵与向量的乘积是线性变换。利用这一点我们可以将任何线性变换表达成矩阵和向量的乘积。

![matrix_linear_trans](../images/maxtrix_linear_trans.png)

$T:R^2\rArr R^3$，第一步是找到$R^2$的标准矩阵，即图中所示矩阵I2。I2可以看作是两个列向量的组合，对每个列向量进行要求的线性变换，得到的矩阵就是线性变换的矩阵。任意二维向量乘上那个矩阵就可以得到这个二维向量在指定变换下的结果。

T(A)是A在T下的像（image），$\{T(\vec{x})\in y | \vec{x}\in A\}$。像是从定义域的一个子集到值域的一个子集；原像是从值域的一个子集到定义域的一个子集。

![preimage](../images/preimage.png)

像和原像和函数与反函数的概念差不多，只是原像中的值不必全部都映射到像中，只要有一部分就可以了。举个例子，假设我们有一个在T转换下的像a，并求出了这个像的原像，那么这个原像的像b是像a的一个子集。

假如有$T(B)=\{0\}$,那么B是变换T的核（kernel），记作Ker(T)。即以下集合中的元素被称为变换T的核。$\{x\in R^2 | T(\vec{x}=\{\vec{0}\}\}$。定义域$R^2$中满足T变换下得到0的向量集合。如果这个变换$T=A\vec{x}$，那么$ker(T)=N(A)$

![matrix_addition_multiplication](../images/matrix_mul_add.png)

上图展示了矩阵与矩阵的加法和矩阵与标量的加法。非常简单的定义，矩阵相加就是把每一个对应的元素相加，矩阵与标量相乘就是把矩阵的每一项与标量相乘。

![rotation](../images/rotation.png)

利用矩阵构建出想要的线性变换。首先判断要映射的维数，如这里是$R^2$到$R^2$，需要一个2x2的单位矩阵（即除了左上到右下的对角线上是一，其余都是0）。找到矩阵后在单位矩阵上作想要的变换。例如延y轴缩放x倍的操作只需要在矩阵的每一个列向量表示y的分量上乘以x就得到了缩放变换。上图是旋转$\theta$角度的变换，利用了单位圆的知识。

![unit_vector](../images/unit_vector.png)

为什么现在才学单位向量……单位向量的定义是模长为1，与普通向量的表达方式不同，顶上不是箭头而是一个小三角。找单位向量先求出要标准化的向量的模长，然后用模长的倒数乘以原向量，即可得到单位向量。

![projection](../images/projection.png)

投影这个名字非常形象，它求的就是$\vec{x}$向量在某一条直线上的“影子”。想象有一根竹竿斜着插在土地上，太阳正好与地面垂直。这根竹竿就是向量，影子就是它的投影。求投影有个公式:求向量x在直线L上的投影，$Proj(\vec{x})=(\frac{\vec{x}\vec{v}}{\vec{v}\vec{v}})\vec{v}$。向量v是构成直线L的向量，简单理解为与L同方向的向量。如果向量v是单位向量，$\vec{v}\vec{v}=||\vec{v}||^2$，即等于1，可以省去分母。也可以用矩阵表达，因为投影本身是一种线性变换。

![composition](../images/composition.png)

函数可以复合，变换的概念很像函数，所以有没有复合变换呢？当然有。有一种变换T将向量x从$R^m$映射到$R^n$，得到向量y；变换S将向量y从$R^n$映射到$R^l$，这就是复合变换，可以表示为$T\circ S=B(A\vec{x})=C\vec{x}=BA\vec{x}$。B和A分别为T和S变换的矩阵；复合变换可以整体看作线性变换，用矩阵C表示。$B(A\vec{x})$也可以表达成$BA\vec{x}$，故$C\vec{x}=BA\vec{x}$。由此我们得到了矩阵相乘的定义：B是一个l x m矩阵，A由u个列向量组成(m x u矩阵)，则$BA=[B\vec{a1},B\vec{a2}...B\vec{au}]$。乘法定义的条件是A的列数等于B的行数。矩阵相乘符合结合律，$(AB)C=A(BC)$；也符合分配律，$A(B+C)=AB+AC$。一定要记得矩阵不符合交换律，$AB\not ={BA},A(B+C)\not ={(B+C)A},AB+AC\not ={BA+CA}$，甚至很多情况都是未定义。

![identity_function](../images/identity_function.png)

不知道是不是因为我没有认真看，这个单位函数怎么这么怪呢？看起来单位函数的定义是映射到自己的函数，即$f(x)=x$。可以表达为$f\circ g=Iy$，g是f的反函数。相当于从y映射到x后又映射回了y，满足自己映射自己的定义。借助单位函数我们可以知道f的反函数是唯一的。假设函数g和h都是f的反函数，那么$g=Ix\circ g=(h\circ f)\circ g$，这是单位函数的定义。$h\circ (f\circ g)=h\circ Iy$，得证g和h相同，故反函数是唯一的。

### 满射(Surjective,onto)和单射(injective,one-to-one)

上面提到过，值域不等于上域，即值域的大小小于等于上域。如果一个函数的值域完全等于上域，即上域中任意的y都是至少一个x的像，那么我们说次函数满射。单射指的是一个函数的值域最多是一个x的像。如果同时有两个x得到同一个y，那么这个函数就不满足单射。如果一个函数的值域既完全覆盖上域也不会有x重复得到一个y，那么这个函数既满射也单射。对于一个从x映射到y的函数f，当且仅当这个函数是满射和单射的时候，此函数可逆。

先来看看如何判断一个函数是否满射。函数可以被看作一种变换，用T表示。当且仅当$C(A)=R^m$，T的矩阵A的每一个列向量都是主列，即拥有m个主变量。更好的记法是矩阵A得列变量可以张成$R^m$。还有另一种判断方式。我们知道Rank(A)=C(A)的基向量数，那满射的条件也可以记作$T为满射\iff Rank(A)=m$。

假设$A\vec{x}=\vec{b}$有解，则其解集满足$\{\vec{x}+n|n\in N(A)\}$。变换T是单射的条件为其矩阵的秩等于n，也就是其零空间中只能有0向量，所以只有一个解；如果零空间只包含0向量，就说明它所有的列都是线性无关的，意味着它们都是基的一部分。还可以反过来说，如果矩阵的秩为n就意味着其所有列向量都是线性无关的，则零空间中就只有0向量，故只有一个解。

把满射和单射的条件结合起来并简化一下，我们就得到了变换可逆性的判断条件。$T:R^n\rArr R^m,T(X)=A(m*n)\vec{x}$仅在矩阵A的行简化阶梯形等于n*n的单位矩阵时可逆。

![inverse_matrix](../images/inverse_matrix.png)

一个找逆矩阵的办法。首先将矩阵A加上单位矩阵转化为增广矩阵，然后逐步将矩阵A化为行简化阶梯形（能成功转化证明矩阵A可逆，否则不可逆）。如果可逆则最开始的单位矩阵经过转化后就成为了矩阵A的逆矩阵。

![determinant](../images/determinant.png)

无论是2\*2还是3\*3矩阵，只要矩阵的行列式为0则该矩阵就没有对应的逆矩阵。

![nn_determinant](../images/nn_determinant.png)

虽然2*\2和3\*3矩阵的行列式都被定义了，但是n\*n怎么办？不可能全部都定义一遍吧。于是数学家们利用了将复杂问题转换为已知问题的思想，给出了n\*n矩阵的递归定义法。具体做法就是先选择一列，从左往右不断缩减所要求的矩阵，直到矩阵被缩小到2\*2。

![nn_determinant_example](../images/nn_determinant_example.png)

选择0较多的行会比较轻松。比如这道题选第一行也能做，第四行也能做，但是选择第四行会比第一行轻松。另外行列式的符号是交错的，如果怕忘记可以看左边那个符号表，对照着写符号就不容易错了。

![rule_of_Sarrus](../images/rule_of_Sarrus.png)

公式有点难记，那这个规律就是帮助记忆3\*3矩阵的行列式的。把原矩阵多写两列，你会发现行列式的结果就是几个对角线的和与差。

假如一个n\*n的矩阵A中的一列与k相乘，相乘后的行列式$det(A')=k*det(A)$，即k倍的原行列式。如果每一列都与k相乘，则$det(kA)=k^n*det(A)$。

![determinant_addition](../images/determinant_addition.png)

这种行列式加法仅适用于这种情况：正好有3个n\*n矩阵，分别为X，Y，Z，X和Y只有一行不一样，Z在X和Y不一样的那一行正好等于x+y。否则以上规律不适用。

如果一个矩阵包含重复的列，则这个矩阵不可能通过行变换化成单位矩阵，或者说不可逆。

假设有一个n\*n的矩阵B，第j个列向量为$\vec{r}j$。如果我们把这个向量加上c倍的任意一个B矩阵的其他列向量，矩阵B的行列式不变。

![triangle_determinant](../images/triangle_determinant.png)

像上图那样的三角矩阵（以从左上到右下的对角线为分割，下面的部分全是0，上面的部分包括对角线为任意数字）的行列式仅仅就是对角线的乘积。如果下面全是0则叫“上三角形矩阵”；如果反过来上面全是0则叫“下三角形矩阵”。下三角形矩阵的行列式同样是对角线的乘积。

2\*2矩阵的行列式还有这么一个意义：其行列式的绝对值等于其列向量组成的平行四边形的面积。

行列式还有一个作用。把一个变换表达为矩阵形式后，$T(\vec{x})=B\vec{x}$。那么原向量$\vec{x}$应用变换后形成的面积是原来向量面积的$det(B)$倍。即行列式可以用来判断应用变换后所形成的面积相对原来的倍数。

![matrix_transpose](../images/matrix_transpose.png)

如果对同一个矩阵进行两次转置，结果会得到最初的矩阵。应该挺好理解的，就是把行和列交换一下而已。对一个任意矩阵进行转置，结果的行列式等于原来的矩阵，即转置不会改变行列式的值。

$C=AB,D=B^TA^T,C^T=(AB)^T=B^TA^T$。有关转置矩阵乘积的性质。简略就是$(AB)^T=B^TA^T$。可以推广到多个矩阵。$(XYZ)^T=Z^TY^TX^T$

还有最后两个性质。$(A+B)^T=A^T+B^T$。$(A^-1)^T$是$A^T$的逆矩阵，换句话说$(A^T)^-1=(A^-1)^T$。$A^-1$表示A的逆矩阵，markdown好像打不了多项式乘方？

向量也有转置，自然也有性质。$\vec{v}·\vec{w}=\vec{v}^T\vec{w}$。$(A\vec{x})·\vec{y}=\vec{x}·(A^T\vec{y})$

![row_and_leftnull_space](../images/row_and_leftnull_space.png)

行空间(rowspace)就是矩阵A的转置矩阵的列空间。因为$A^T$的列向量等于A的行向量，所以相对来说$A^T$张成的空间等于原矩阵的行空间。左零空间(left nullspace)满足$N(A^T)=\{\vec{x}|A^T\vec{x}·\vec{0}\}=\{\vec{x}|\vec{x}^TA=\vec{0}^T\}$。零空间的定义是$\{\vec{x}|\vec{x}A=\vec{0}\}$，左零空间由于调换了向量x和矩阵A的位置，把向量x放到左边了，故叫左零空间。

$C(A^T)$(任意矩阵A的行空间)与$N(A)$（$A^T$的左零空间）互为正交补；$N(A^T)$（任意矩阵A的左零空间）与$C(A)$（$A^T$的行空间）互为正交补。

还有一个在上面的图中有提到但是很小一个可能会被漏掉的性质。$Rank(A)=Rank(A^T)$

如果$A^TA$是线性无关的，并且是一个方阵，那么$rref(A^T)=I(k)$,那么$A^TA$是可逆的。

### 正交补集

$V^o=\{\vec{x}\in R^n|\vec{x}·\vec{v}=0\}$。补集对于每一个$\vec{v}\in V$都成立。在V的右上角画一个垂直符号来表示是V的正交补集（markdown不知道怎么打这个符号,就用右上角o来表示）。

关于正交补集的两个性质。$N(A)=(C(A^T))^o$和$N(B^T)=(C((B^T)^T))^o$。说大白话可能更容易理解。零空间是行空间的正交补集；左零空间是列空间的正交补集。

假设$A^T$是一个k*n的矩阵，其行向量为$\vec{v1}^T,\vec{v2}^T...\vec{vt}^T$，那么$Rank(A)+Nullity(A^T)=n,dim(C(A))+dim(N(A^T))=n,dim(v)+dim(v^o)=n$。

![represent_vector](../images/represend_vector.png)

$\vec{a}\in R^n,\vec{a}=\vec{v1}+\vec{x1}$。向量a是$R^n$中的一个元素，那么向量a可以表达成$R^n$的子空间V中的元素加上子空间V的正交补中的元素，且这种组合表达是唯一的。一个子空间和其补集是有交集的，交集的元素仅有$\vec{0}$。一个子空间的补集的补集等于原来的子空间，不会出现补集的补集在原子空间范围之外的情况。

对于$\vec{b}\in C(A)$，存在一个唯一解$r0\in C(A^T)$使得r0是$A\vec{x}=\vec{b}$的解且没有其他更小解。

之前学过投影，不过定义只是对于在一条线上的投影。$Proj(L)\vec{x}$是一个在直线L上的向量，使得$\vec{x}-Proj(L)\vec{x}$正交于L。推广到平面的投影也是适用的。$Proj(V)\vec{x}$是一个满足$\vec{v}\in V$唯一的向量，使得$\vec{x}=\vec{v}+\vec{w}$，$\vec{w}$是$V^o$中唯一的成员。有点绕，换种说法。$Proj(V)\vec{x}$等于某个在V中的唯一向量，使得$\vec{x}-Proj(V)\vec{x}$正交于V中的任意一个成员。更简洁的表达：$\vec{x}-Proj(V)\vec{x}\in V^I$，$Proj(V)\vec{x}$就是第一个定义提到的$\vec{v}$，$\vec{x}-Proj(V)\vec{x}$就是第一个定义提到的$\vec{w}$

平面上的投影跟直线上的投影一样，都是线性变换。$Proj(V)\vec{x}=A(A^TA)^jA^T\vec{x},j=-1$。$A(A^TA)^jA^T$整体是一个矩阵。如果已知V的基向量，让这些列向量等于某个矩阵A的列向量，然后应用上面的变换，就得到了对平面投影的线性变换表达。

![closest_vector](../images/closest_vector.png)

这张图证明了一个向量到其对平面的投影的长度小于等于这个平面上任意的向量。其实不用证明大家应该也能看出来，挺明显的。

![least_squares](../images/least_squares.png)

最小二乘解适用于解形似$A\vec{x}=\vec{b}$的方程无解的情况。当此方程无解时，表明向量b不在矩阵A的列空间内，从而找不到向量x使其等同于向量b。但最小二乘解可以在A的列空间中找到一个解，且该解在列空间所有的向量中距离向量b最近。之前有提到在某个平面与某个向量最近的向量是它在平面上的投影，公式也是这么推出来的。$A^TA\vec{x}^*=A^T\vec{b}$，$\vec{x}^*$就是最小二乘解。

![transformation_matrix_basis](../images/transformation_matrix_basis.png)

平时用的坐标系可以看作是以$R^2$的标准基矩阵得到的。我们也可以拿其他的向量作为基底来表示目标向量，向量x对基向量B的表示方式为$[\vec{x}]B$(B应该是下标但是我不知道怎么打)，互相转换方式为$C^-1\vec{x}$和$C[\vec{x}]B=\vec{x}$，C是以B中的每个向量作为列向量的矩阵。

![transformation_matrix](../images/transformation_matrix.png)

标准坐标下的线性变换可以用矩阵来表示，相对坐标肯定也可以，但使用同一个矩阵肯定行不通。向量x相对B的坐标需要使用矩阵D来得到B下的坐标。它们的关系可以用一张图来表示。

![diagram](../images/diagram.png)

左上角的图中，$\vec{x}$和$[\vec{x}]B$是同一个向量的不同表示；$T(\vec{x})$和$[T\vec{x}]B$也是同一个向量经过同一个变换后的不同表示。不同表示之间可以用乘以矩阵D来转换。

![orthonormal_bases](../images/orthonormal_bases.png)

正交标准集B的定义是：B中所有向量模长为1，且互相正交。如果V为正交标准集中向量张成的空间，则可以说B是V的一个标准正交基底。标准正交基底可以大大简化平面上的投影公式，如下。

![orthonormal_basis_projection](../images/orthonormal_basis_projection.png)

$Proj(V)\vec{x}=AA^T\vec{x}$，当$A=[\vec{v1}\vec{v2}...\vec{vk}]$，A中的列向量为V的正交标准集中的向量。